Article: unisex-names

Tokenized by nltk.word_tokenize 
Token analysis before pre-processing 
Raw number of tokens: 3
Raw number of types: 3
Raw Type token ratio (higher = more diversity in language use): 1.0

100 most freq tokens before (pre)processing: 
[(',', 39), ('<', 31), ('>', 31), ('the', 30), ('in', 20), ('of', 17), ('nobarlabels', 13), ('drivers', 11), ('.', 10), ('bar', 9), ('a', 9), ('/bar', 9), ('to', 8), ('that', 8), ('and', 7), ('on', 7), ('’', 6), ('insurance', 6), ('for', 6), ('$', 6), ('where', 5), ('are', 5), ('state', 5), ('(', 5), (')', 5), ('than', 5), ('average', 5), ('percent', 5), ('crashes', 4), ('was', 4), ('collisions', 4), ('were', 4), ('involved', 4), ('national', 4), ('—', 4), ('s', 3), ('car', 3), ('each', 3), ('out', 3), ('is', 3), ('but', 3), ('million', 3), ('billion', 3), ('miles', 3), ('traveled', 3), ('i', 2), ('your', 2), ('three', 2), ('data', 2), ('america', 2), ('number', 2), ('those', 2), ('how', 2), ('much', 2), ('companies', 2), ('all', 2), ('across', 2), ('country', 2), ('at', 2), ('texas', 2), ('don', 2), ('t', 2), ('any', 2), ('them', 2), ('good', 2), ('according', 2), ('fatal', 2), ('more', 2), ('north', 2), ('every', 2), ('latest', 2), ('far', 2), ('figures', 2), ('be', 2), ('new', 2), ('most', 2), ('expensive', 2), ('collision', 2), ('idahoans', 2), ('best', 2), ('come', 2), ('costing', 2), ('insurers', 2), ('2010.', 2), ('still', 2), ('they', 2), ('show', 2), ('politics', 2), ('or', 2), ('an', 2), ('candidate', 2), ('polls', 2), ('want', 1), ('try', 1), ('answer', 1), ('question', 1), ('using', 1), ('types', 1), ('historic', 1), ('could', 1)]

Applied pre-processing:
Lowercased all tokens 
Tokens below minimum token length 2 filtered out
Punctuation filtered out ['!', '"', '#', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '=', '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '~', '“', '’', '”', '—', "'", '<', '>']
Words filtered out: ['facebooktwitteremail', 'nobarlabels', 'nolinelabels', 'nolabels']

Applied filters: 
barlabelsonly = True
bigrams = False
bothlabels = False
lemmatize = False
linelabelsonly = False
minimumtokenlength = 2
showuniquepostagtokens = True
stemmer = False
stopwords = False
trigrams = False

Token analysis after pre-processing 
Number of tokens: 0
Number of types: 0
Type token ratio: 0

Used nouns, verbs and adjectives in article: 
(tokens separated by , ) 
100 most freq tokens after processing: 
[('the', 30), ('in', 20), ('bar', 18), ('of', 17), ('drivers', 11), ('to', 8), ('that', 8), ('and', 7), ('on', 7), ('insurance', 6), ('for', 6), ('where', 5), ('are', 5), ('state', 5), ('than', 5), ('average', 5), ('percent', 5), ('crashes', 4), ('was', 4), ('collisions', 4), ('were', 4), ('involved', 4), ('national', 4), ('car', 3), ('each', 3), ('out', 3), ('country', 3), ('is', 3), ('but', 3), ('million', 3), ('billion', 3), ('miles', 3), ('traveled', 3), ('your', 2), ('three', 2), ('data', 2), ('america', 2), ('number', 2), ('those', 2), ('how', 2), ('much', 2), ('companies', 2), ('all', 2), ('across', 2), ('at', 2), ('texas', 2), ('don', 2), ('any', 2), ('them', 2), ('good', 2), ('according', 2), ('fatal', 2), ('more', 2), ('north', 2), ('every', 2), ('2011', 2), ('latest', 2), ('far', 2), ('figures', 2), ('be', 2), ('new', 2), ('most', 2), ('expensive', 2), ('collision', 2), ('idahoans', 2), ('best', 2), ('come', 2), ('costing', 2), ('insurers', 2), ('2010', 2), ('still', 2), ('they', 2), ('show', 2), ('politics', 2), ('or', 2), ('an', 2), ('candidate', 2), ('polls', 2), ('voters', 2), ('want', 1), ('try', 1), ('answer', 1), ('question', 1), ('using', 1), ('types', 1), ('historic', 1), ('could', 1), ('indicate', 1), ('worst', 1), ('especially', 1), ('driver', 1), ('negligent', 1), ('some', 1), ('way', 1), ('pay', 1), ('charge', 1), ('measures', 1), ('vary', 1), ('lot', 1), ('no', 1)]
