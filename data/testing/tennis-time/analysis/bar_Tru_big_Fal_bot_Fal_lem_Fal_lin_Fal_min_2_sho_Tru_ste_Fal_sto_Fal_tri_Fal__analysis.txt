Article: tennis-time

Tokenized by nltk.word_tokenize 
Token analysis before pre-processing 
Raw number of tokens: 3
Raw number of types: 3
Raw Type token ratio (higher = more diversity in language use): 1.0

100 most freq tokens before (pre)processing: 
[('<', 124), ('>', 124), (',', 119), ('the', 112), ('of', 77), ('in', 62), ('nobarlabels', 50), ('that', 42), ('.', 39), ('a', 39), ('bar', 37), ('and', 37), ('/bar', 37), ('’', 36), ('to', 35), ('than', 28), ('percent', 24), ('more', 23), ('films', 21), ('s', 20), ('for', 20), ('is', 18), ('(', 16), ('was', 16), (')', 16), ('on', 15), ('at', 14), ('women', 13), ('are', 12), ('other', 12), ('it', 12), ('drivers', 11), ('—', 11), ('we', 11), ('all', 9), ('found', 9), ('median', 9), ('any', 8), ('average', 8), ('$', 8), ('as', 8), ('only', 8), ('have', 8), ('between', 8), ('who', 8), ('boomers', 8), ('use', 8), ('each', 7), ('but', 7), ('t', 7), ('were', 7), ('had', 7), ('be', 7), ('most', 7), ('with', 7), ('test', 7), ('days', 7), ('where', 6), ('state', 6), ('those', 6), ('insurance', 6), ('country', 6), ('national', 6), ('over', 6), ('from', 6), ('less', 6), ('still', 6), ('they', 6), ('about', 6), ('one', 6), ('among', 6), ('year', 6), ('number', 5), ('some', 5), ('how', 5), ('by', 5), ('involved', 5), ('while', 5), ('compared', 5), ('an', 5), ('like', 5), ('budget', 5), ('lower', 5), ('“', 5), ('”', 5), ('said', 5), ('50', 5), ('used', 5), ('drugs', 5), ('age', 5), ('countries', 5), ('three', 4), ('data', 4), ('crashes', 4), ('much', 4), ('out', 4), ('don', 4), ('them', 4), ('collisions', 4), ('2012', 4)]

Applied pre-processing:
Lowercased all tokens 
Tokens below minimum token length 2 filtered out
Punctuation filtered out ['!', '"', '#', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '=', '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '~', '“', '’', '”', '—', "'", '<', '>']
Words filtered out: ['facebooktwitteremail', 'nobarlabels', 'nolinelabels', 'nolabels']

Applied filters: 
barlabelsonly = True
bigrams = False
bothlabels = False
lemmatize = False
linelabelsonly = False
minimumtokenlength = 2
showuniquepostagtokens = True
stemmer = False
stopwords = False
trigrams = False

Token analysis after pre-processing 
Number of tokens: 0
Number of types: 0
Type token ratio: 0

Used nouns, verbs and adjectives in article: 
(tokens separated by , ) 
100 most freq tokens after processing: 
[('the', 112), ('of', 77), ('bar', 74), ('in', 62), ('that', 42), ('and', 37), ('to', 35), ('than', 28), ('percent', 25), ('more', 23), ('films', 21), ('for', 20), ('is', 18), ('was', 16), ('on', 15), ('at', 14), ('women', 13), ('are', 12), ('other', 12), ('it', 12), ('drivers', 11), ('we', 11), ('all', 9), ('found', 9), ('median', 9), ('any', 8), ('average', 8), ('as', 8), ('only', 8), ('have', 8), ('between', 8), ('who', 8), ('boomers', 8), ('use', 8), ('days', 8), ('each', 7), ('country', 7), ('but', 7), ('were', 7), ('had', 7), ('be', 7), ('most', 7), ('with', 7), ('year', 7), ('test', 7), ('where', 6), ('state', 6), ('those', 6), ('insurance', 6), ('national', 6), ('over', 6), ('from', 6), ('less', 6), ('still', 6), ('they', 6), ('about', 6), ('one', 6), ('50', 6), ('among', 6), ('number', 5), ('some', 5), ('how', 5), ('by', 5), ('involved', 5), ('while', 5), ('compared', 5), ('an', 5), ('like', 5), ('budget', 5), ('lower', 5), ('said', 5), ('used', 5), ('drugs', 5), ('age', 5), ('countries', 5), ('three', 4), ('data', 4), ('crashes', 4), ('much', 4), ('out', 4), ('don', 4), ('them', 4), ('collisions', 4), ('2012', 4), ('has', 4), ('higher', 4), ('same', 4), ('so', 4), ('you', 4), ('when', 4), ('or', 4), ('bechdel', 4), ('2013', 4), ('film', 4), ('two', 4), ('sample', 4), ('investment', 4), ('budgets', 4), ('this', 4), ('alcohol', 4)]
