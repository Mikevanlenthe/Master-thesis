Article: inconvenient-sequel

Tokenized by nltk.word_tokenize 
Token analysis before pre-processing 
Raw number of tokens: 3
Raw number of types: 3
Raw Type token ratio (higher = more diversity in language use): 1.0

100 most freq tokens before (pre)processing: 
[(',', 63), ('the', 60), ('<', 57), ('>', 57), ('of', 36), ('in', 34), ('that', 31), ('a', 26), ('to', 22), ('bar', 21), ('/bar', 21), ('films', 21), ('’', 18), ('and', 17), ('.', 17), ('nobarlabels', 15), ('on', 13), ('for', 13), ('than', 13), ('women', 13), ('drivers', 11), ('percent', 11), ('s', 10), ('at', 10), ('was', 9), ('we', 9), ('(', 8), (')', 8), ('—', 8), ('found', 8), ('$', 8), ('are', 7), ('more', 7), ('test', 7), ('median', 7), ('each', 6), ('state', 6), ('insurance', 6), ('were', 6), ('between', 6), ('where', 5), ('those', 5), ('is', 5), ('but', 5), ('involved', 5), ('average', 5), ('budget', 5), ('data', 4), ('crashes', 4), ('out', 4), ('all', 4), ('t', 4), ('collisions', 4), ('national', 4), ('other', 4), ('had', 4), ('higher', 4), ('it', 4), ('only', 4), ('when', 4), ('with', 4), ('have', 4), ('bechdel', 4), ('2013', 4), ('film', 4), ('investment', 4), ('one', 4), ('budgets', 4), ('“', 4), ('”', 4), ('car', 3), ('how', 3), ('don', 3), ('them', 3), ('million', 3), ('2012', 3), ('according', 3), ('billion', 3), ('miles', 3), ('traveled', 3), ('from', 3), ('be', 3), ('still', 3), ('compared', 3), ('an', 3), ('movie', 3), ('released', 3), ('gross', 3), ('two', 3), ('about', 3), ('lower', 3), ('return', 3), ('sample', 3), ('1970', 3), ('our', 3), ('passing', 3), ('i', 2), ('your', 2), ('using', 2), ('three', 2)]

Applied pre-processing:
Lowercased all tokens 
Tokens below minimum token length 2 filtered out
Punctuation filtered out ['!', '"', '#', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '=', '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '~', '“', '’', '”', '—', "'", '<', '>']
Words filtered out: ['facebooktwitteremail', 'nobarlabels', 'nolinelabels', 'nolabels']

Applied filters: 
bigrams = False
bothlabels = False
lemmatize = False
minimumtokenlength = 2
onlybarlabels = True
onlylinelabels = False
showuniquepostagtokens = True
stemmer = False
stopwords = False
trigrams = False

Token analysis after pre-processing 
Number of tokens: 0
Number of types: 0
Type token ratio: 0

Used nouns, verbs and adjectives in article: 
(tokens separated by , ) 
100 most freq tokens after processing: 
[('the', 60), ('bar', 42), ('of', 36), ('in', 34), ('that', 31), ('to', 22), ('films', 21), ('and', 17), ('on', 13), ('for', 13), ('than', 13), ('women', 13), ('percent', 12), ('drivers', 11), ('at', 10), ('was', 9), ('we', 9), ('found', 8), ('are', 7), ('more', 7), ('test', 7), ('median', 7), ('each', 6), ('state', 6), ('insurance', 6), ('were', 6), ('between', 6), ('where', 5), ('those', 5), ('is', 5), ('but', 5), ('involved', 5), ('average', 5), ('budget', 5), ('data', 4), ('crashes', 4), ('out', 4), ('all', 4), ('collisions', 4), ('national', 4), ('other', 4), ('had', 4), ('higher', 4), ('it', 4), ('only', 4), ('when', 4), ('with', 4), ('have', 4), ('bechdel', 4), ('2013', 4), ('film', 4), ('sample', 4), ('investment', 4), ('one', 4), ('budgets', 4), ('car', 3), ('how', 3), ('country', 3), ('don', 3), ('them', 3), ('million', 3), ('2012', 3), ('according', 3), ('billion', 3), ('miles', 3), ('traveled', 3), ('from', 3), ('be', 3), ('still', 3), ('compared', 3), ('an', 3), ('movie', 3), ('released', 3), ('gross', 3), ('two', 3), ('about', 3), ('lower', 3), ('return', 3), ('1970', 3), ('our', 3), ('passing', 3), ('your', 2), ('using', 2), ('three', 2), ('america', 2), ('number', 2), ('much', 2), ('companies', 2), ('across', 2), ('texas', 2), ('do', 2), ('well', 2), ('any', 2), ('by', 2), ('good', 2), ('56', 2), ('which', 2), ('16', 2), ('accounted', 2), ('fatal', 2)]
