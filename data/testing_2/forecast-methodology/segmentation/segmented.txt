Sentence nr: 0
Sep. 17, 2014 at 7:30 AM How The FiveThirtyEight Senate Forecast Model Works By Nate Silver Filed under 2014 Midterms Get the data on GitHub GitHub data at data/forecast-methodology FacebookTwitterEmail UPDATE (Sept. 21, 2016; 9 a.m.): The article below describes the methodology for our 2014 Senate forecasts.

Sentence nr: 1
In all the important ways, our model for predicting the 2016 Senate elections works the same way and abides by the same principles.

Sentence nr: 2
The FiveThirtyEight Senate forecast model launched earlier this month.

Sentence nr: 3
Right now, it shows Republicans with about a 53 percent chance of picking up the Senate next year.

Sentence nr: 4
We owe you a lot more detail about how that forecast is calculated and how it might change between now and Nov. 4 — and how our model differs from some of the others out there.

Sentence nr: 5
This article, which outlines the model’s methodology, is going to be on the detailed side.

Sentence nr: 6
I’ve tried to keep the descriptions in plain language as often as possible (the footnotes get somewhat more technical).

Sentence nr: 7
But it’s meant to be a reasonably comprehensive reference guide rather than breezy bedtime reading.

Sentence nr: 8
First, however, I want to describe the principles behind the model.

Sentence nr: 9
Some of these are more philosophical and abstract — they describe what I think of as best practices for applied statistical modeling.

Sentence nr: 10
I can get passionate about this stuff — but somewhat contrary to the media portrayal of election forecasters as wizards who conjure up spells from their spreadsheets, our goal is not to divine some magic formula that miraculously predicts every election.

Sentence nr: 11
Instead, it’s to make sense of publicly available information in a rigorous and disciplined way.

Sentence nr: 12
Principle 1: A good model should be probabilistic, not deterministic.

Sentence nr: 13
The FiveThirtyEight model produces probabilistic forecasts as opposed to hard-and-fast predictions.

Sentence nr: 14
In the same sense a weather forecaster might tell you there’s a 20 percent chance of rain tomorrow, the FiveThirtyEight model might estimate the Democrat has a 20 percent chance of winning the Senate race in Kentucky.

Sentence nr: 15
My view is that this is often the most important part of modeling — and often the hardest part.

Sentence nr: 16
Predictions of the most likely outcome (“The Democrat will win the race by 3 percentage points”) are sometimes relatively immune to changes in methodology.

Sentence nr: 17
But probabilistic forecasts can be very sensitive to them.

Sentence nr: 18
Does that 3-point lead translate into a 60 percent chance of winning?

Sentence nr: 19
Or a 95 percent chance?

Sentence nr: 20
Or what?

Sentence nr: 21
This can be tricky.

Sentence nr: 22
Quick-and-dirty assumptions, like that the margin of error expressed in a poll is a complete reflection of its accuracy, sometimes don’t hold up well in the real world.

Sentence nr: 23
In our database of polls conducted in the final three weeks of campaigns since 1998, the actual results fell outside of the poll’s reported margin of error almost 25 percent of the time.

Sentence nr: 24
So it’s important to model the error empirically — based on how well the polls have done in past races — instead of taking shortcuts.

Sentence nr: 25
In fact, while FiveThirtyEight’s forecasts are sometimes seen as extremely bold when compared with news media coverage of campaigns, they are fairly conservative compared with some other forecasting models.

Sentence nr: 26
For a variety of reasons, statistical models are prone toward overconfidence unless they’re designed carefully.

Sentence nr: 27
The best test of a probabilistic forecast is whether it’s well calibrated.

Sentence nr: 28
By that I mean: Out of all FiveThirtyEight forecasts that give candidates about a 75 percent shot of winning, do the candidates in fact win about 75 percent of the time over the long run?

Sentence nr: 29
It’s a problem if these candidates win only 55 percent of the time.

Sentence nr: 30
But from a statistical standpoint, it’s just as much of a problem if they win 95 percent of the time.

Sentence nr: 31
Fortunately, FiveThirtyEight’s Senate forecasts have historically been well calibrated.

Sentence nr: 32
We’ve posted the data on GitHub so that you can check them out for yourself.

Sentence nr: 33
<bar>For example, out of the 12 instances where we gave a candidate between an 85 percent and a 95 percent chance of winning on Election Day, the favored candidate won in 11 cases, or 92 percent of the time.</bar> We also have a track record of being well calibrated in other types of election forecasts and sports forecasts.

Sentence nr: 34
Principle 2: A good model ought to be empirical.

Sentence nr: 35
Simplicity can be a virtue in model-building, but every model must be reasonably consistent with the evidence.

Sentence nr: 36
It’s one thing to have stress-tested your model, determined that only a few things really matter, and removed all the superfluous bits.

Sentence nr: 37
But if you don’t account for a certain variable or some statistical property in your model, you may be making an implicit assumption that it doesn’t matter much — when sometimes it does.

Sentence nr: 38
For instance, it’s probably wrong to treat registered voter polls the same as likely voter polls when there’s reasonably clear historical evidence that registered voter polls tend to overrate the standing of Democrats.

Sentence nr: 39
As I mentioned, it’s almost certainly wrong to assume the error in a poll is fully captured by its reported margin of error.

Sentence nr: 40
It’s also wrong to assume that the error in one poll is independent from the next — about as often as not, the polls all miss in the same direction, which can lead to late-breaking “waves” toward one or the other party.

Sentence nr: 41
It’s also important to check whether modeling choices have a sound basis in theory.

Sentence nr: 42
One variable our model uses is an ideology score for each candidate, which seeks to estimate how liberal or conservative he or she is relative to voters in his or her state.

Sentence nr: 43
This variable is highly statistically significant in predicting election outcomes — but just as important is that it has a strong basis in the political science literature (in this case, see the median voter theorem).

Sentence nr: 44
By contrast, if we’d found that past election outcomes had been well predicted by the number of consonants a candidate had in her middle name, we’d strongly suspect this was a statistical fluke and we wouldn’t include it in our model.

Sentence nr: 45
Principle 3: A good model ought to respond sensibly to changes in inputs.

Sentence nr: 46
Models that gyrate around wildly with the slightest provocation should be viewed skeptically.

Sentence nr: 47
So should those unmoved by even important-seeming information.

Sentence nr: 48
The FiveThirtyEight Senate model tends to produce fairly stable forecasts.

Sentence nr: 49
That can make things a bit dull from day to day; most of the time, the new polls and data we collect have little effect on the bottom line.

Sentence nr: 50
But now and then almost all the polls on a particular day favor one or the other party, and the overall forecast for Senate control moves by a few percentage points in that party’s direction.

Sentence nr: 51
There will sometimes be more volatility in the forecast toward the end of the campaign because late changes in the polls can’t be reversed before Election Day.

Sentence nr: 52
A sports analogy is helpful here: An NFL team that kicks a field goal with two minutes to play in the first quarter becomes only a 59 percent favorite to win, but one that does so with two minutes to play in the fourth quarter becomes an 83 percent favorite.

Sentence nr: 53
Likewise, a 2-point shift in the polls can produce a larger change in win probabilities late in an election.

Sentence nr: 54
Principle 4: A good model ought to avoid changing its rules in midstream.

Sentence nr: 55
We’re sometimes guilty of talking about the FiveThirtyEight model as though it has a mind of its own.

Sentence nr: 56
It doesn’t.

Sentence nr: 57
It’s just a computer program — and we wrote the program.

Sentence nr: 58
However we don’t “tweak” the forecast in a given state just because we don’t like the outcome.

Sentence nr: 59
And we avoid changing the program once we’ve launched the forecasts.

Sentence nr: 60
Nor do we change it that much from year to year — the Senate model is perhaps 80 percent to 90 percent the same as when we launched it in 2008, and is also largely similar to our presidential forecast model.

Sentence nr: 61
All versions of these models have used polling along with non-polling data, have been probabilistic rather than deterministic, and so forth.

Sentence nr: 62
Speaking of that model — what does it do, exactly?

Sentence nr: 63
There are seven major steps.

Sentence nr: 64
Step 1: Weighted polling average We start by collecting polls — lots of polls.

Sentence nr: 65
There are only a few types of polls we discard.

Sentence nr: 66
First are those from pollsters that we know or suspect to have faked their results or to have engaged in other gross ethical misconduct — for instance, Strategic Vision and Research 2000.

Sentence nr: 67
Next, we exclude internal polls conducted directly on behalf of candidates or party organizations like the Democratic Senatorial Campaign Committee and the Republican National Committee, which tend to be inaccurate and biased.

Sentence nr: 68
We err strongly on the side of inclusiveness; the threshold for excluding a poll is high.

Sentence nr: 69
The model has a lot of other defense mechanisms, particularly in minimizing the effect of polls that show signs of partisan bias through our “house effects” adjustment (which I’ll describe in Step 2).

Sentence nr: 70
For more about our philosophy on this, see this discussion.

Sentence nr: 71
A poll is weighted based on three factors: How recently it was conducted.

Sentence nr: 72
Older polls are penalized through an exponential decay formula.

Sentence nr: 73
The penalty becomes stiffer — that is, more emphasis is placed on recency — the closer we get to the election.

Sentence nr: 74
Our research suggests that the news media place too much emphasis on recency and would be better off looking at a broader range of polls.

Sentence nr: 75
The poll’s sample size.

Sentence nr: 76
Polls that sample more voters receive a larger weight, although there are diminishing returns.

Sentence nr: 77
In particular, we’ve found that the improvement in accuracy from sampling more voters is not as large in practice as it’s supposed to be in theory.

Sentence nr: 78
The reasons for this are interesting — we’ll discuss them more when we release our pollster ratings.

Sentence nr: 79
But the implication is that one should be careful about weighting an otherwise dubious poll heavily just because it took a large sample.

Sentence nr: 80
This reflects a slight refinement from previous years, when the model placed more emphasis on sample size.

Sentence nr: 81
The pollster rating.

Sentence nr: 82
We’ve released an entirely new set of pollster ratings for 2014 and explain the process for calculating them in much more depth in a separate article.

Sentence nr: 83
The method is similar to one we used in 2010, however, in that pollsters are rated on the basis of both their past accuracy16 and on two easily measurable proxies for methodological quality.

Sentence nr: 84
First, is whether the polling firm is a member of industry groups and initiatives like the AAPOR Transparency Initiative.

Sentence nr: 85
And second is whether the firm regularly calls cellphones in addition to landlines.

Sentence nr: 86
These factors don’t tell you everything you need to know about a poll — but they tend to be correlated with other strong methodological practices.

Sentence nr: 87
More importantly, these methodological variables are strong predictors of more accurate polling results going forward.

Sentence nr: 88
Truth be told, the poll weights don’t always make a huge impact — although this year could be an exception given how many close races there are.

Sentence nr: 89
The main way to go wrong is probably in placing too much emphasis on the most recent polls, which can lead to unwarranted volatility.

Sentence nr: 90
A few bits of housekeeping on other polling situations that come up from time to time: Pollsters routinely poll the same races multiple times.

Sentence nr: 91
In these cases, we don’t “throw out” the old poll, but it gets a lower weight; see here for how that works.

Sentence nr: 92
If a pollster lists both likely voter and registered voter results, we use the likely voter version.

Sentence nr: 93
In other cases where the pollster releases multiple versions of the same poll — for instance, results drawn from two different turnout models, or results with and without a minor candidate included — we simply average all applicable versions together.

Sentence nr: 94
Tracking polls, which contain overlapping dates in their samples, are weighted based on the number of new respondents in each edition of the poll.

Sentence nr: 95
Step 2: Adjustments to the polling average The FiveThirtyEight model performs three sets of adjustments to the polls: a likely voter adjustment, a house effects adjustment and (usually the least important of three) a trend line adjustment.

Sentence nr: 96
The rationale for the likely voter adjustment is explained at some length here.

Sentence nr: 97
<bar>Polls of likely voters are almost always more favorable to Republicans than polls of broader samples, like registered voters.</bar> But polls of likely voters also tend to be more accurate and less biased, especially in midterm years.

Sentence nr: 98
So as a default, the FiveThirtyEight model shifts registered voter polls (and polls of all adults) toward Republicans to make them more comparable to likely voter surveys.

Sentence nr: 99
In particular, the model defaults to shifting polls of registered voters toward Republicans by 2.7 percentage points, which is the historical average difference between likely voter and registered voter polls in midterm years.

Sentence nr: 100
However, the magnitude of the shift is updated based on polls like this one that list both registered voter and likely voter results in the same survey.

Sentence nr: 101
So far this year, the average gap has been just above 3 points.

Sentence nr: 102
The house effects adjustment accounts for the tendency of some polling firms to consistently show more favorable results for one or the other party.

Sentence nr: 103
It works by means of a regression analysis on all Senate and generic congressional ballot polls.

Sentence nr: 104
This is one of a number of reasonable ways of comparing a poll against others of the same state.

Sentence nr: 105
However, one or two (or even a few) polls may not tell you that much about a pollster’s house effect; variation from other pollsters may just be statistical noise instead.

Sentence nr: 106
Furthermore, a model without some tolerance for differences of opinion among pollsters may deprive itself of the benefits of aggregating polls together in the first place.

Sentence nr: 107
The FiveThirtyEight model handles this by calculating a “buffer zone” based on the number of polls a firm has released.

Sentence nr: 108
For instance, a firm with relatively few polls might have a buffer zone of 2 percentage points.

Sentence nr: 109
Any house effect beyond that buffer zone is subtracted from the poll, so a polling firm with a 5-point Republican house effect and a 2-point buffer zone will have its results adjusted toward Democrats by 3 points.

Sentence nr: 110
A new feature in the model this year is that house effects from past years are used to help calibrate the house effects adjustment.

Sentence nr: 111
However, their influence is relatively minor.

Sentence nr: 112
House effects are generally fairly consistent from election to election, but there are exceptions; for instance, the firm Rasmussen Reports, which had a strong Republican house effect the past, has little house effect so far this year.

Sentence nr: 113
The main case where this is helpful is when a firm with a long history of partisan polling drops in to poll a few races after having been dormant for most of the cycle.

Sentence nr: 114
Another question is how to calculate the baseline that other polls are compared against.

Sentence nr: 115
We use a weighted average, where the weight is based on the number of polls a firm has released and its pollster rating.

Sentence nr: 116
This means that the baseline is determined mostly by what the stronger polling firms are saying.

Sentence nr: 117
In 2012, this worked to Democrats’ benefit — the higher-rated polling firms tended to show stronger results for them — but we’ve observed no such consistent pattern this year.

Sentence nr: 118
The trend line adjustment is an important part of the FiveThirtyEight presidential model, but not so important in the Senate model.

Sentence nr: 119
In forecasting the presidential race, you can make accurate inferences about how the polls are changing in one state based on how they’re changing in other states.

Sentence nr: 120
For instance, if Barack Obama had gained several points relative to Mitt Romney in both Michigan and Minnesota, you could be almost certain that he’d also gained ground in Wisconsin even if Wisconsin hadn’t been polled recently.

Sentence nr: 121
In Senate elections, however, there are different candidates on the ballot in each state — so the inferences are much weaker.

Sentence nr: 122
Instead, the FiveThirtyEight trend line adjustment is calculated solely based on generic congressional ballot polls.

Sentence nr: 123
It works by looking for changes in the generic congressional ballot as tracked by the same polling firms over the same sample populations — for instance, Quinnipiac polls of registered voters — and then backing out a time trend by means of a lowess smoothing regression.

Sentence nr: 124
See here for more detail.

Sentence nr: 125
The trend line adjustment currently detects some Republican movement on the generic ballot.

Sentence nr: 126
However, the adjustment is applied conservatively in the Senate model.

Sentence nr: 127
It currently shifts the polling average in each state toward Republicans by an average of only 0.2 percentage points.

Sentence nr: 128
Let’s interrupt here to draw some probability distributions.

Sentence nr: 129
One narrative holds that there are big differences between those Senate models that look only at polls and those that look at polls along with other factors.

Sentence nr: 130
But it’s more complicated than that.

Sentence nr: 131
In recent days, running our model based on the adjusted polling average alone (after Step 2) would reduce the GOP’s chances of controlling the Senate by about 5 percent — it doesn’t make a huge difference.

Sentence nr: 132
What’s a more complete story?

Sentence nr: 133
Small differences matter this year because both individual states and the overall Senate race are so close.

Sentence nr: 134
Most election models (including ours) work in something like the following way: First, they calculate the most likely outcome in a particular state (“The Republican wins by 1 point”) and then they determine the degree of uncertainty around that estimate.

Sentence nr: 135
Most models do this by means of a normal distribution or something similar to it.

Sentence nr: 136
In this type of statistical distribution, all outcomes within the margin of error are not equally likely; instead, those closer to the mean of the distribution are more probable.

Sentence nr: 137
The graphic below, for example, illustrates a normal distribution with a mean of +1 (as in, a candidate is ahead by 1 point in the polls) and a standard deviation of 5.

Sentence nr: 138
In this example, we’ll take positive values to mean the Republican wins the race and negative values to mean the Democrat does.

Sentence nr: 139
According to the normal distribution, the Republican will win 58 percent of the time.

Sentence nr: 140
But if we shift the center of the distribution by just 1 point toward the Republican — say, our model averages the polls together a little differently than someone else’s, and it projects her to win by 2 points instead of 1 — it has a noticeable effect on the probabilities.

Sentence nr: 141
Not huge, but noticeable: She’s gone from being a 58 percent favorite to a 66 percent favorite.

Sentence nr: 142
By contrast, if we’d given the Republican an additional point when she was already well ahead, it wouldn’t make much difference.

Sentence nr: 143
If she were up by 10 points in the polls, for instance, she’d already be a 97.7 percent favorite according to the normal distribution; putting her up by 11 points instead would only increase that chance to 98.6 percent.

Sentence nr: 144
However, there’s another way we can affect the candidate’s win probability: by changing the standard deviation.

Sentence nr: 145
In the example below, I’ve kept the Republican’s lead at 2 points.

Sentence nr: 146
But I’ve reduced the standard deviation to 2 points instead of 5.

Sentence nr: 147
Now, with that mere 2-point lead she’s suddenly an 84 percent favorite to win.

Sentence nr: 148
In my view, far too little attention is paid to those questions.

Sentence nr: 149
What is the uncertainty in the forecast, as opposed to the most likely result?

Sentence nr: 150
I don’t like to call out other forecasters by name unless I have something positive to say about them — and we think most of the other models out there are pretty great.

Sentence nr: 151
But one is in so much perceived disagreement with FiveThirtyEight’s that it requires some attention.

Sentence nr: 152
That’s the model put together by Sam Wang, an associate professor of molecular biology at Princeton.

Sentence nr: 153
That model is wrong — not necessarily because it shows Democrats ahead (ours barely shows any Republican advantage), but because it substantially underestimates the uncertainty associated with polling averages and thereby overestimates the win probabilities for candidates with small leads in the polls.

Sentence nr: 154
This is because instead of estimating the uncertainty empirically — that is, by looking at how accurate polls or polling averages have been in the past — Wang makes several assumptions about how polls behave that don’t check out against the data.

Sentence nr: 155
There’s a rich record of those assumptions failing and resulting in highly overconfident forecasts.

Sentence nr: 156
In 2010, for example, Wang’s model made Sharron Angle the favorite in Nevada against Harry Reid; it estimated she was 2 points ahead in the polls, but with a standard error of just 0.5 points.

Sentence nr: 157
If we drew a graphic based on Wang’s forecast like the ones we drew above, it would have Angle winning the race 99.997 percent of the time, meaning that Reid’s victory was about a 30,000-to-1 long shot.

Sentence nr: 158
To be clear, the FiveThirtyEight model had Angle favored also, but it provided for much more uncertainty.

Sentence nr: 159
Reid’s win came as a 5-to-1 underdog in our model instead of a 30,000-to-1 underdog in Wang’s; those are very different forecasts.

Sentence nr: 160
There are a number of other examples like this.

Sentence nr: 161
Wang projected a Republican gain of 51 seats in the House in 2010, but with a margin of error of just plus or minus two seats.

Sentence nr: 162
His forecast implied that odds against Republicans picking up at least 63 seats (as they actually did) were trillions-and-trillions-to-1 against.

Sentence nr: 163
If you want a “polls only” model that estimates the uncertainty more rigorously, I’d recommend The Huffington Post’s or Drew Linzer’s.

Sentence nr: 164
I wanted to get that out of the way before proceeding to the state fundamentals calculation, which is one of the more complicated and “controversial” parts of the FiveThirtyEight model — but also one that ultimately doesn’t have that much influence on the forecast.

Sentence nr: 165
Step 3: Calculate state fundamentals In presidential elections, as I mentioned earlier, you can take advantage of the fact that the same two candidates are on the ballot in each state.

Sentence nr: 166
This makes it much easier to make comparisons from one state to the next.

Sentence nr: 167
That isn’t true for Senate races, where the state fundamentals are a rough guide; they miss the final margin in the race by an average of something like 9 percentage points.

Sentence nr: 168
Why bother at all?

Sentence nr: 169
One reason is that you sometimes have no alternative; the occasional Senate race gets literally no polling.

Sentence nr: 170
Or it gets very limited polling.

Sentence nr: 171
In states like Alaska and Kansas this year, we have little idea of what’s going on from the polls alone.

Sentence nr: 172
It helps to have some backstop, like knowing that both states are extremely Republican-leaning.

Sentence nr: 173
Another reason to look beyond polls is to prevent abrupt shifts in the forecast.

Sentence nr: 174
For instance, the recent strong polling for Republicans in Kentucky or for Democrats in Michigan put those races more in line with how our fundamentals calculation has them.

Sentence nr: 175
In any event, the state fundamentals estimate is based on a series of non-polling indicators that have historically shown some predictive power in Senate races; their relative importance is determined by regression analysis.

Sentence nr: 176
The indicators are as follows: The generic congressional ballot.

Sentence nr: 177
This provides an indication of the overall partisan mood in the country.

Sentence nr: 178
As of this writing, the FiveThirtyEight model has the generic ballot favoring the Republicans by about 3 percentage points.

Sentence nr: 179
Congressional approval ratings.

Sentence nr: 180
This is the other national indicator.

Sentence nr: 181
It doesn’t work toward the benefit of either party — instead, it informs the model about the overall amount of antipathy toward incumbents regardless of their party.

Sentence nr: 182
Right now, congressional approval ratings remain near their historic lows, which mitigates some of the incumbency advantage.

Sentence nr: 183
Fundraising totals.

Sentence nr: 184
Fundraising data is a useful indicator for a number of reasons: It can reflect the grassroots support for a candidate, or a candidate’s overall level of organization — and money can be exchanged for goods and services like advertisements and a better turnout operation.

Sentence nr: 185
Our model specifies this variable as the proportion of funds raised by each major-party candidate.

Sentence nr: 186
For instance, if the Democrat has raised $3 million and the Republican has raised $1 million, the Democrat has raised 75 percent of the money.

Sentence nr: 187
This definition accounts for the diminishing returns associated with additional fundraising.42 The FiveThirtyEight model looks only at the sum of individual public contributions — as opposed to funds raised through PACs or “Super PACs,” funds donated by the parties, or funds contributed by the candidates themselves.

Sentence nr: 188
So far this year, this is one of the reasons for Democrats to be optimistic — they’ve outraised Republicans by our definition in almost all of the most important Senate races.

Sentence nr: 189
Highest elected office held.

Sentence nr: 190
This is among the less important variables43 but it has some influence.

Sentence nr: 191
We rate candidates on a 4-point scale based on the highest office they’ve been elected to: 3 points for current or former governors or senators — by definition including all elected incumbent senators; 2 points for members of the House of Representatives, candidates holding statewide elected office (like state attorneys general and lieutenant governors) and mayors of large cities; 1 point for other nontrivial elected offices, such as state senator or state representative; 0 points for candidates who have never been elected to any substantive position.

Sentence nr: 192
Margin of victory in most recent Senate election.

Sentence nr: 193
This variable applies to elected incumbents only.

Sentence nr: 194
Past victory margin is not a terribly reliable indicator — the political mood can shift a lot in six years — but it does tell you something.

Sentence nr: 195
Victory margins are adjusted relative to the national climate in the re-election year.

Sentence nr: 196
That hurts this year’s crop of Democratic incumbents, since most of them were last elected in 2008, a high-water mark for the party.

Sentence nr: 197
For instance, Sen. Kay Hagan of North Carolina won her race by an impressive 8.5 percentage points against Elizabeth Dole in 2008 — but that came in an environment when Democrats won the national popular vote for the U.S. House by 10.6 percentage points.

Sentence nr: 198
That implies Hagan might not have won her election in a neutral political environment.

Sentence nr: 199
Candidates who did not face major-party opposition in their last re-election bid, such as Mark Pryor of Arkansas, are treated as having won re-election by about 40 percentage points.

Sentence nr: 200
Candidate ideology and state partisanship.

Sentence nr: 201
You can think of these as two variables or as one — the FiveThirtyEight model links them together.

Sentence nr: 202
It estimates the conservative-liberal ideology of a candidate and then compares it against the estimated ideology of voters in the state.

Sentence nr: 203
The larger the difference between them, the worse the candidate is expected to perform.

Sentence nr: 204
The candidate ideology scores are based on an unweighted average of three systems, which are described at more length here: DW-Nominate scores, which reflect a candidate’s voting record in Congress; CFscores — created by Adam Bonica of Stanford University — which estimate left-right ideology based on the identity of a candidate’s donors; OnTheIssues.org scores, which reflect public statements made by the candidate on a series of policy issues ranging from gay marriage to tax policy.

Sentence nr: 205
The score from each system is normalized such that each has the same average and standard deviation — this allows for a direct comparison among them.

Sentence nr: 206
We in turn estimate the ideology of voters in each state based on two variables: Presidential results relative to the national average in 2012 and 2008; The winners of recent past congressional races in the state — as measured by the average DW-Nominate score of the state’s congressional delegation over the past four Congresses.

Sentence nr: 207
This helps to account for states — for example, Arkansas — that vote very Republican for president but sometimes still elect Democrats to Congress.

Sentence nr: 208
This variable can make some difference.

Sentence nr: 209
In a purple state that votes exactly in line with the national average, a “mainstream” Republican would be expected to perform a net of 4 percentage points better than a more conservative, so-called tea party Republican.

Sentence nr: 210
This variable, for instance, helped to predict Sen. Claire McCaskill’s victory over the conservative Republican Todd Akin in Missouri in 2012.

Sentence nr: 211
However, the Republican nominees this year are more moderate.

Sentence nr: 212
Among the more important Senate races, the state fundamentals estimate slightly hurts Democrats in Alaska, Kentucky, Louisiana, Minnesota and North Carolina, and slightly helps them in Arkansas, Georgia and Iowa.

Sentence nr: 213
Its most important effect is in Kansas, where a center-left independent candidate, Greg Orman, is polling slightly ahead of the Republican incumbent, Pat Roberts, but where the fundamentals calculation has Roberts as a heavy favorite.

Sentence nr: 214
However, the polling average and the fundamentals calculation have some tendency to converge toward one another, as has already happened in some states, such as Michigan.

Sentence nr: 215
Step 4: Now-cast/snapshot This part is pretty simple.

Sentence nr: 216
The adjusted polling average (Step 2) and the state fundamentals estimate (Step 3) are combined into a single number that projects what would happen in an election held today.

Sentence nr: 217
We’ve sometimes referred to this as the “now-cast” or “snapshot.” This works by treating the state fundamentals estimate as equivalent to a “poll” with a weight of 0.35.

Sentence nr: 218
What does that mean?

Sentence nr: 219
Our poll weights are designed such that a 600-voter poll from a firm with an average pollster rating gets a weight of 1.00 (on the day of its release; this weight will decline as the poll ages).

Sentence nr: 220
Only the lowest-rated pollsters will have a weight as low as 0.35.

Sentence nr: 221
So the state fundamentals estimate is treated as tantamount to a single bad (though recent) poll.

Sentence nr: 222
This differs from the presidential model, where the state fundamentals estimate is more reliable and gets a considerably heavier weight.

Sentence nr: 223
In states with abundant recent polling, the state fundamentals calculation makes almost no difference.

Sentence nr: 224
As of this writing, for instance, it gets only 6 percent of the overall weight in Kentucky and 7 percent in Iowa.

Sentence nr: 225
However, it has more influence on states with less polling; the state fundamentals currently get 15 percent of the weight in Alaska, for example, and 23 percent in Delaware.

Sentence nr: 226
As the election approaches, the state fundamentals tend to get less and less weight because the volume of polling increases.

Sentence nr: 227
Step 5: Election Day forecast The FiveThirtyEight model is explicitly meant to be a forecast of how the election will turn out on Nov. 4, 2014 — rather than an estimate of what would happen in an election held today.

Sentence nr: 228
Looking toward the future means there’s more uncertainty in the forecast — we’ll discuss that in Step 6.

Sentence nr: 229
In addition, the model might anticipate an overall shift toward one party or another, although this has only a minor influence on the forecast at this point in the race.

Sentence nr: 230
In our presidential model, we calculate a projection of the national popular vote based on an economic index.

Sentence nr: 231
This estimate also reflects the benefit of incumbency.

Sentence nr: 232
You might think of this as an estimate of the “national fundamentals” (as opposed to the state fundamentals).

Sentence nr: 233
In 2012, it suggested that Obama would win the national popular vote by about 2 percentage points.59 Whenever Obama established a polling lead of more than 2 percentage points, such as after the Democratic convention, this calculation subtracted something from his lead in the polls to forecast the Election Day result.

Sentence nr: 234
And whenever Obama’s lead fell below 2 points, such after the first presidential debate in Denver, it added something to it.

Sentence nr: 235
Put more technically, the model assumed that Obama’s result would revert toward the mean of how past incumbents had performed under similar economic conditions.

Sentence nr: 236
However, the model was designed such that the weight placed on the national fundamentals declined over the course of the campaign — until it was zero by Election Day.

Sentence nr: 237
If the polls had shown Obama with an 11-point lead by Election Day, or Romney with a 9-point lead, that’s what the model would have shown — even though such a result would have been inconsistent with how economic conditions had affected presidential races in the past.

Sentence nr: 238
We’ve introduced a similar step into our Senate model this year in order to make it more consistent with our presidential model.

Sentence nr: 239
However, the Senate version is quite a bit simpler and has less overall influence on the forecast.

Sentence nr: 240
Specifically, the model assumes the generic congressional ballot will revert toward a mean of favoring the opposition party — in this case, Republicans — by about 5 percentage points as of Election Day, which is the ballot’s historic average performance in midterm elections since 1990.

Sentence nr: 241
It does not account for economic conditions, presidential approval ratings, the favorability of the parties or any other factor.

Sentence nr: 242
As in the presidential model, however, the weight placed on this historic average decreases as the election year goes on — it’s already quite small, and it will be zero by Election Day.

Sentence nr: 243
Furthermore, the Democrats’ position on the generic ballot has already declined to show a deficit with Republicans of about 3 percentage points, not much different from the long-term average.61 For these reasons, Step 5 barely changes the results — currently, it shows Republicans doing only about 0.2 percentage points better in each state than they would otherwise.62 It would make more difference earlier in the election year, or if the generic ballot were way out of line with historical trends.

Sentence nr: 244
Step 6: Estimate margin of error If you’ve gotten this far, you’ll know that I think this step is important.

Sentence nr: 245
As I’ve said, the goal of the FiveThirtyEight model is not to “call” races but instead to estimate the probability that each candidate will win.

Sentence nr: 246
And some races are associated with more uncertainty than others.

Sentence nr: 247
This is nicely illustrated by our interactive Senate forecast — the picture below reflects how it looked as of Tuesday evening.

Sentence nr: 248
The dots in the chart represent the most likely outcomes.

Sentence nr: 249
The gray bars indicate the uncertainty (more precisely, the 90 percent prediction interval).

Sentence nr: 250
In Colorado, for instance, while the most likely outcome is a win for the Democratic candidate by about 3 percentage points, the prediction interval runs all the way from a 12-point Democratic win to a 6-point win for the Republican.

Sentence nr: 251
That’s already a fairly wide range — and remember, it captures only 90 percent of the cases.

Sentence nr: 252
There’s also a 5 percent chance that the Democrat will win by more than 12 points and a 5 percent chance that the Republican will win by more than 6.

Sentence nr: 253
However, the prediction interval is even wider in some states, especially Kansas, Alaska and Louisiana.

Sentence nr: 254
How are these intervals determined?

Sentence nr: 255
We’ve done it by looking at which factors are historically correlated with larger errors in the forecast — and we’ve identified six important ones.

Sentence nr: 256
Most of these ought to be pretty intuitive.

Sentence nr: 257
Uncertainty is larger the when there are more days to go until the election.

Sentence nr: 258
This means the model will become more confident as Election Day approaches.

Sentence nr: 259
Uncertainty is larger when there are fewer polls.

Sentence nr: 260
This year’s election has featured fewer polls than elections in the recent past (and also lower-quality polls), which makes the uncertainty higher than it was in 2008, 2010 or 2012.

Sentence nr: 261
Note that the uncertainty is estimated on a state-by-state basis, so relatively well-polled states like Georgia are associated with less uncertainty than thinly polled ones like Alaska.

Sentence nr: 262
Uncertainty is larger when the polls disagree more with one another.

Sentence nr: 263
Take one state where two polls have the Democrat ahead by 5 points and another where the Democrat is tied with the Republican in one poll but 10 points ahead in another.

Sentence nr: 264
The Democrat has a 5-point lead in the polling average in both states.

Sentence nr: 265
But there is considerably more uncertainty, we’ve found, in the state where the polls disagree with one another.

Sentence nr: 266
Uncertainty is larger when the polling average disagrees more with the state fundamentals.

Sentence nr: 267
Another reason for calculating the “state fundamentals” estimate — however much weight you place on it — is to get a sense for whether it tells a consistent story with the polls.

Sentence nr: 268
We’ve found that in states where there is more divergence between polls and fundamentals — as in Kansas this year — the uncertainty is much higher.

Sentence nr: 269
Uncertainty is larger when there are more undecideds or third-party voters in the polls.

Sentence nr: 270
This is another intuitive assumption that checks out in the data.

Sentence nr: 271
A lot of Senate races this year feature high numbers of undecided voters, something that contributes to high uncertainty about their outcomes.

Sentence nr: 272
Races with viable third-party candidates are also associated with very high volatility.

Sentence nr: 273
Uncertainty is larger when the race is more lopsided.

Sentence nr: 274
This is the one counterintuitive-seeming finding; isn’t the outcome more in doubt when the polls show a close race?

Sentence nr: 275
Of course it is — if you’re concerned about who will win.

Sentence nr: 276
But as measured by the difference between the polled and the actual margin in the race, the error tends to be larger when there is a bigger gap separating the candidates.

Sentence nr: 277
It’s fairly common, for instance, for a candidate up by 40 points in the polls to win her race by 30 points or 50 points instead.

Sentence nr: 278
Step 7: Simulate outcomes and estimate the probability of each party controlling the Senate Once we’ve completed Step 6, we’ve calculated what amounts to a mean (“The Republican is ahead by 2 points”) and a standard deviation (“plus or minus 5 points”) for the forecast in each state.

Sentence nr: 279
As I mentioned, you can use a normal distribution to calculate a candidate’s win probability from these two factors alone.

Sentence nr: 280
So why not just stop there?

Sentence nr: 281
One minor reason is because the FiveThirtyEight model does not quite use a normal distribution; instead it uses a transformation of the normal distribution with slightly fatter tails.

Sentence nr: 282
The transformation gives extreme long-shot candidates slightly shorter odds; it might mean, for example, that we would have a candidate with a 0.5 percent chance to win his race instead of a 0.05 percent chance.

Sentence nr: 283
But this process is not complicated and makes little difference.

Sentence nr: 284
Instead, we run simulations to deal with a couple of more important problems.

Sentence nr: 285
One is that the error in the polls is not independent from state to state.

Sentence nr: 286
In a number of recent elections, one party has either gained considerable ground in the closing stages of the race (as Democrats did in 2006), or the polls have had a strong overall bias toward one party or another on Election Day itself (as in 1994, 1998 and 2012).

Sentence nr: 287
This property is not as pronounced as in presidential races, where the same two candidates are on the ballot in each state.

Sentence nr: 288
But it happens often enough to worry about.

Sentence nr: 289
As I mentioned in Step 6, the model estimates the overall amount of error in each state based on the number of days until the election, the volume of polling there, the number of undecided voters and other factors.

Sentence nr: 290
Before running the simulations, the model breaks the error down into two subcomponents: national error and state-specific error.

Sentence nr: 291
National error68 affects every state in the same way; state-specific error, as its name implies, affects one state at a time.

Sentence nr: 292
In each simulation, the program draws a series of random numbers.

Sentence nr: 293
The first number it draws represents national error; in one simulation, for instance, the draw might be “Republicans +2.” This means that Republicans will outperform their forecasts by 2 percentage points in every state in that simulation.

Sentence nr: 294
Then it draws another number in each state.

Sentence nr: 295
Perhaps in Arkansas, for instance, it comes up with “Democrats +5.” These numbers are then added together to produce a simulated result in each state.

Sentence nr: 296
In Arkansas in this example, it would mean the Democrat, Mark Pryor, outperformed his projection by 3 percentage points (despite Democrats having a poor night nationally).

Sentence nr: 297
If Pryor had trailed his opponent by fewer than 3 points (or led by any margin), that would be enough to win him the race in that simulation.

Sentence nr: 298
If he’d been behind more than 3 points, he’d still come up short.

Sentence nr: 299
In this way, we can estimate not only each candidate’s chance of winning but also the overall number of seats each party will control, specifically accounting for the possibility that it could be a year like 1994 or 2012 when almost all of the races broke in the same direction.

Sentence nr: 300
The simulation is also helpful for handling viable third-party candidates such as Larry Pressler of South Dakota who present a couple of additional challenges.

Sentence nr: 301
One is that the range of outcomes for third-party candidates is not symmetric.

Sentence nr: 302
A third-party candidate polling at 15 percent with some time to go in the race has some chance (not a lot) of gaining 20 points and finishing at 35 percent, in which case he could win.

Sentence nr: 303
(As I’ve mentioned; vote shares for third-party candidates can be volatile.)

Sentence nr: 304
But he has no chance of losing 20 points and finishing at -5 percent.73 So we model the vote shares for third-party candidates based on a log-normal distribution, which accounts for this type of asymmetry.

Sentence nr: 305
Also, third-party candidates are often closer to one of the major-party candidates ideologically and therefore are more likely to “trade” votes with that candidate.

Sentence nr: 306
In the Maine gubernatorial election in 2010, for example, the independent, Eliot Cutler, was left of center and much closer to the Democrat, Libby Mitchell, than to the conservative Republican candidate, Paul LePage.

Sentence nr: 307
When Cutler suddenly began to gain ground late in the race, almost all of his votes were taken from Mitchell rather than from LePage.

Sentence nr: 308
The model accounts for this by using the ideology scores we calculated in Step 4.

Sentence nr: 309
In South Dakota, for example, Pressler’s vote share (Pressler is a former Republican) is more correlated with the Republican, Mike Rounds, than the Democrat, Rick Weiland.

Sentence nr: 310
So in those simulations where Pressler does well, he takes more of his votes from Rounds.

Sentence nr: 311
Likewise, when Pressler does poorly, he gives back most of his votes to Rounds.

Sentence nr: 312
The very last step is simply counting up the number of seats won in each simulation, and adding them to the baseline of 34 Democratic seats and 30 Republican seats that are not up for grabs this year.

Sentence nr: 313
The model assigns any third-party winners to one of the major parties; see here for more on how we do that.

Sentence nr: 314
Greg Orman of Kansas has said he’ll caucus with whichever party is “clearly in the majority.” (This produces a kink in our probability distribution.)

Sentence nr: 315
But based on Orman’s ideology score, he’s assigned a 75 percent probability of caucusing with Democrats in the event his vote would determine majority control.

Sentence nr: 316
Finally, we can tally the results across thousands of simulations to estimate the likelihood of a party finishing with a given number of seats.

Sentence nr: 317
That produces a probability distribution that looks like this: Simulations with 50-50 ties are resolved as producing Democratic control because of the tiebreaking vote of Vice President Joe Biden.

Sentence nr: 318
So we count up the percentage of simulations in which Democrats finished with at least 50 seats; that represents their chances of retaining the Senate.

Sentence nr: 319
The remaining cases go to the Republicans.

Sentence nr: 320
Got any other questions?

Sentence nr: 321
Just drop me a line.

Sentence nr: 322
We’ll have more in the coming days, including new pollster ratings and more detail on our forecast page.

Sentence nr: 323
CORRECTION (Sept. 17, 9:23 a.m.): An earlier version of this story incorrectly referred to the Congress serving in the years 2007-08 as the 109th Congress.

Sentence nr: 324
It was the 110th.

Sentence nr: 325
CORRECTION (Sept. 17, 11:34 a.m.): An earlier version of a footnote to this story gave the wrong state for where the Republican Bill Cassidy is running for Senate.

Sentence nr: 326
He is running in Louisiana, not Kentucky.

Sentence nr: 327
CORRECTION (Sept. 17, 3:50 p.m.): An earlier version of this article misstated the percentage of cases in which a candidate we favored between 85 percent and 95 percent actually won.

Sentence nr: 328
The article correctly stated that it was 11 in 12 cases, but that percentage is 92 percent, not 89 percent.

