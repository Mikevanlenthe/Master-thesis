Tokenized by nltk.word_tokenize 
Token analysis before pre-processing 
Raw number of tokens: 12
Raw number of types: 11
Raw Type token ratio: 0.9166666666666666

Applied pre-processing:
Lowercased all tokens 
Punctuation filtered out ['!', '"', '#', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '~', '“', '’', '”', '—', "'"]
Words filtered out: ['facebooktwitteremail', '']

Applied filters:
Using stopwords filter = True
Using lemmatizer = False
Using stemmer = False

Token analysis after pre-processing 
Number of tokens: 28
Number of types: 27
Type token ratio: 0.9642857142857143

Used nouns, verbs and adjectives in article: 
(tokens separated by whitespace) 
('NNS', 'articles files readmefiles')

('VBD', 'scraped found found articlesscraped found109 scraped115readme')

('NN', 'readme article sfound found128 articlesscraped115 readmefilesfound filesfound109 found109article articleurls urlsfound sfound128')

('JJ', 'scraped115 articleurl urls')

