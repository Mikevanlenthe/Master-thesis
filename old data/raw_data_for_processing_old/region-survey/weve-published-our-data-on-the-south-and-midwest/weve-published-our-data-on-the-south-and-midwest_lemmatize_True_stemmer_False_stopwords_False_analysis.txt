Tokenized by nltk.word_tokenize 
Token analysis before pre-processing 
Raw number of tokens: 327
Raw number of types: 174
Raw Type token ratio: 0.5321100917431193

Applied pre-processing:
Lowercased all tokens 
Punctuation filtered out ['!', '"', '#', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '~', '“', '’', '”', '—', "'"]
Words filtered out: ['facebooktwitteremail', '']

Applied filters:
Using stopwords filter = False
Using lemmatizer = True
Using stemmer = False

Token analysis after pre-processing 
Number of tokens: 156
Number of types: 114
Type token ratio: 0.7307692307692307

Used nouns, verbs and adjectives in article: 
(tokens separated by whitespace) 
('VBN', 'published filed')

('NNS', 'data data data people data missouri data remixes data remixes')

('JJS', 'midwest midwest midwest')

('NN', 'walt hickey remix interest post result audience poll state github page response south survey head folk information didn code income gender region approach column interest language analysis respondent word approach code expatriate definition region explain inability core state state identity article ross bechdel test thing research kickoff point question point endeavor region insight')

('VBD', 'wrote format excited asked split posted resulted')

('JJ', 'tuesday surveymonkey south available github make such respondent interesting interested southern midwestern local midwestern resident difficulttocategorize such fantastic interesting send walterhickey fivethirtyeightcom whole nebulous')

('VBG', 'using making explaining finding')

('VBP', 'make find mean want live agree virginia')

('VB', 'tail make please send post learn appreciated')

('JJR', 'more')

