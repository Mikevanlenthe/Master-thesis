Tokenized by nltk.word_tokenize 
Token analysis before pre-processing 
Raw number of tokens: 327
Raw number of types: 174
Raw Type token ratio: 0.5321100917431193

Applied pre-processing:
Lowercased all tokens 
Punctuation filtered out ['!', '"', '#', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '~', '“', '’', '”', '—', "'"]
Words filtered out: ['facebooktwitteremail', '']

Applied filters:
Using stopwords filter = False
Using lemmatizer = True
Using stemmer = True

Token analysis after pre-processing 
Number of tokens: 156
Number of types: 105
Type token ratio: 0.6730769230769231

Used nouns, verbs and adjectives in article: 
(tokens separated by whitespace) 
('JJ', 'publish tuesday surveymonkey south make such analysi southern midwestern local midwestern inabl resid difficulttocategor such ident articl send walterhickey fivethirtyeightcom whole')

('NNS', 'data data respons data data missouri pleas data data particularli')

('JJS', 'midwest midwest midwest')

('NN', 'walt hickey file remix interest post wednesday result audienc poll state make avail github github page survey head folk inform didn respond code incom gender region interest approach column interest peopl languag ask respond word especi interest approach code expatri definit region agre core state state remix post ross bechdel test result fantast remix interest thing research kickoff point question point endeavor region insight')

('VBD', 'wrote format excit split')

('VBP', 'make find mean want live explain virginia send find')

('VB', 'tail explain make post learn appreci')

('JJR', 'more')

