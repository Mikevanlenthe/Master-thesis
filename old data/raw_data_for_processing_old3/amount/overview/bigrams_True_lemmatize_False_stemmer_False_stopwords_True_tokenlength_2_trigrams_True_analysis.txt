Tokenized by nltk.word_tokenize 
Token analysis before pre-processing 
Raw number of tokens: 12
Raw number of types: 11
Raw Type token ratio: 0.9166666666666666

Applied pre-processing:
Lowercased all tokens 
Tokens below minimum length: 2 filtered out

Punctuation filtered out ['!', '"', '#', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '~', '“', '’', '”', '—', "'"]
Words filtered out: ['facebooktwitteremail', '']

Applied filters:
Using stopwords filter = True
Using lemmatizer = False
Using stemmer = False

Token analysis after pre-processing 
Number of tokens: 32
Number of types: 31
Type token ratio: 0.96875

Used nouns, verbs and adjectives in article: 
(tokens separated by whitespace) 
('NNS', 'articles files readmefiles')

('VBD', 'scraped found found articlesscraped found109 scraped115readme')

('NN', 'readme article url scraped115 sfound found128 articlesscraped115 readmefilesfound filesfound109 found109article articleurls urlsfound sfound128')

('JJ', 'articleurl urls')

