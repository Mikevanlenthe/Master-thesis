Token analysis before pre-processing 
Raw number of tokens: 47
Raw number of types: 46
Raw Type token ratio: 0.9787234042553191

Filters:
Using stopwords filter = True
Using lemmatizer = False
Using stemmer = False

Used nouns, verbs and adjectives in article: 
(tokens separated by whitespace) 
('NN', 'commut obama clemenc grant presid sentenc pardon prison convict announc includ number year drug histori github serv accord issu record inmat relea group percent charli file')

('NNS', 'data prisoners commutations')

('VBG', 'manning')

('VBD', 'respon')

('JJ', 'trump analysi')

('VBP', 'charg')

Token analysis after pre-processing 
Number of tokens: 34
Number of types: 34
Type token ratio: 1.0

