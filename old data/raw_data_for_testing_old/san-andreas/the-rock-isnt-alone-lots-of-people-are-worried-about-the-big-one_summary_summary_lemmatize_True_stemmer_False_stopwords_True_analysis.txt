Token analysis before pre-processing 
Raw number of tokens: 19
Raw number of types: 13
Raw Type token ratio: 0.6842105263157895

Filters:
Using stopwords filter = True
Using lemmatizer = True
Using stemmer = False

Used nouns, verbs and adjectives in article: 
(tokens separated by whitespace) 
('NN', 'areispeoplpercentearthquakthink havemakesurveyknowjunamisn tone walthickey')

('NNS', 'themovidata goyellowstonaccordonerocklotgithubdwaynjohnsonandreas')

('VBP', 'sanit californiaoneone')

('JJR', 'lifetimeregionwestwereworribedisaster')

Token analysis after pre-processing 
Number of tokens: 10
Number of types: 10
Type token ratio: 1.0

