Token analysis before pre-processing 
Raw number of tokens: 51
Raw number of types: 42
Raw Type token ratio: 0.8235294117647058

Filters:
Using stopwords filter = True
Using lemmatizer = True
Using stemmer = False

Used nouns, verbs and adjectives in article: 
(tokens separated by whitespace) 
('NN', 'driver state percent number crash traffic distract record mile colli cost question compani accord state travel percent loss mona driver state answer america driver')

('VBZ', 'averag')

('NNS', 'data')

('JJ', 'dear')

('VBP', 'hope')

Token analysis after pre-processing 
Number of tokens: 28
Number of types: 23
Type token ratio: 0.8214285714285714

