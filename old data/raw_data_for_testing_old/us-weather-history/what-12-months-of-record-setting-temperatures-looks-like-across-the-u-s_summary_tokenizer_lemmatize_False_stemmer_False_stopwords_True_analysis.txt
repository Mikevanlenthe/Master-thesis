Token analysis before pre-processing 
Raw number of tokens: 714
Raw number of types: 186
Raw Type token ratio: 0.2605042016806723

Filters:
Using stopwords filter = True
Using lemmatizer = False
Using stemmer = False

Used nouns, verbs and adjectives in article: 
(tokens separated by whitespace) 
('JJ', 'token true true verbs randy datausweatherhistory june june chart temperature blue tell2 june houston november normal national atmospheric january western united high curious famous large high normal actual high previous unique famous several particular high uncomfortable high upper high february single cold consistent clear last last many cold general different single broad experienced experienced experienced experienced updated aggregate')

('NN', 'analysis number number ratio lemmatizer stemmer article month look olson github github year hotter administration report record world state aboveaverage temperature year janjune period record globe stateofclimate http tcodjwfrfmmjp pictwittercomxpj8rfr8bs july fact period july temperature detail york time show month temperature city chart show record average range year city record year city story chart expand yearround justright temperature heat year march record temperature year setting record seattle winter record spectrum temperature temperature part city temperature month hottest record city city heat snap record climate change part country consequence climate view temperature oceanic noaanceiclimate past handful indicate click charlotte warm average chart affect cold cold weather feel analysis number number ratio')

('VBG', 'preprocessing using using using recordsetting saying recordsetting recordsetting beginning setting recordsetting lasting studying preprocessing')

('NNS', 'tokens types filters stopwords false nouns adjectives tokens data noaa data carolina others houston angeles tokens types')

('VBP', 'type chicago wave make feel wave type')

('VBN', 'token used returned published released recorded expected token token')

('VBD', 'separated half houston filed looked soared reached examined')

('VBZ', 'digit')

('VB', 'take')

('JJS', 'warmest warmest warmest best')

Token analysis after pre-processing 
Number of tokens: 234
Number of types: 150
Type token ratio: 0.6410256410256411

