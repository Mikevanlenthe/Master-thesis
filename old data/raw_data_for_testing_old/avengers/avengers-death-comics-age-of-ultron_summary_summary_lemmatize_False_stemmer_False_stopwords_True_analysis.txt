Token analysis before pre-processing 
Raw number of tokens: 55
Raw number of types: 47
Raw Type token ratio: 0.8545454545454545

Filters:
Using stopwords filter = True
Using lemmatizer = False
Using stemmer = False

Used nouns, verbs and adjectives in article: 
(tokens separated by whitespace) 
('NN', 'death year time join thing friend percent chanc scarlet jump movi github number film coupl life')

('JJ', 'univ destroy iron')

('VBD', 'died sent')

('NNS', 'data avengers')

('VBP', 'sign')

Token analysis after pre-processing 
Number of tokens: 24
Number of types: 24
Type token ratio: 1.0

