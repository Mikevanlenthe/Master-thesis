Tokenized by nltk.word_tokenize 
Token analysis before pre-processing 
Raw number of tokens: 289
Raw number of types: 163
Raw Type token ratio: 0.5640138408304498

Applied pre-processing:
Lowercased all tokens 
Punctuation filtered out ['!', '"', '#', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '~', '“', '’', '”', '—', "'"]
Words filtered out: ['facebooktwitteremail', '']

Applied filters:
Using stopwords filter = False
Using lemmatizer = False
Using stemmer = False

Token analysis after pre-processing 
Number of tokens: 142
Number of types: 111
Type token ratio: 0.7816901408450704

Used nouns, verbs and adjectives in article: 
(tokens separated by whitespace) 
('NN', 'team chance minute game mike beuoy allison mccann basketball github github datanbawinprobs summarize season chart season point game team probability time score situation shot chart team ingame probability minute regulation time winloss record time probability model foundation chart model state share winloss record dominance contrast pull quarter')

('VBG', 'winning winning remaining shooting watching building')

('VBN', 'filed given based made based lost taken shown')

('NNS', 'data data games possessions plays probabilities data seasons simulations games findings warriors hawks paths warriors games leads discoveries comments')

('JJR', 'more more')

('VBD', 'summarized averaged played hawks')

('JJ', 'foul real favorite golden similar different early insurmountable fourth')

('VB', 'develop best reflect')

('VBZ', 'provides uses does')

('VBP', 'atlanta point have know')

