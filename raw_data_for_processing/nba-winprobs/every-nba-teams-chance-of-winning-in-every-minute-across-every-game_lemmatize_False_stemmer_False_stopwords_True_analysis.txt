Tokenized by nltk.word_tokenize 
Token analysis before pre-processing 
Raw number of tokens: 289
Raw number of types: 163
Raw Type token ratio: 0.5640138408304498

Applied pre-processing:
Lowercased all tokens 
Punctuation filtered out ['!', '"', '#', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '~', '“', '’', '”', '—', "'"]
Words filtered out: ['facebooktwitteremail', '']

Applied filters:
Using stopwords filter = True
Using lemmatizer = False
Using stemmer = False

Token analysis after pre-processing 
Number of tokens: 119
Number of types: 92
Type token ratio: 0.773109243697479

Used nouns, verbs and adjectives in article: 
(tokens separated by whitespace) 
('NN', 'team chance minute game mike beuoy allison mccann basketball github github datanbawinprobs summarize season chart shot season point game team probability time score situation chart team ingame probability regulation time winloss record time probability model chart model state share winloss record point dominance contrast pull quarter')

('VBG', 'winning winning remaining watching building')

('VBD', 'filed summarized made averaged played hawks')

('NNS', 'data data games possessions plays probabilities data seasons simulations games findings warriors hawks paths warriors games leads comments')

('VBN', 'given based based lost taken shown')

('JJ', 'shot shooting foul minute real foundation reflect favorite golden similar different early insurmountable fourth')

('VB', 'develop')

('VBZ', 'provides uses discoveries')

('JJS', 'best')

('VBP', 'atlanta know')

