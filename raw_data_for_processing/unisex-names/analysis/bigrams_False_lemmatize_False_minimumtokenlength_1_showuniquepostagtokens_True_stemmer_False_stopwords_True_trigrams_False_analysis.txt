Article: unisex-names

Tokenized by nltk.word_tokenize 
Token analysis before pre-processing 
Raw number of tokens: 632
Raw number of types: 271
Raw Type token ratio: 0.4287974683544304

100 most freq tokens before (pre)processing: 
[(',', 2722), ('the', 1340), ('(', 748), (')', 748), ('.', 734), ("'", 664), ('of', 605), ('in', 587), ('a', 575), ('to', 473), (':', 463), ('our', 420), ('and', 413), ('verdict', 377), ('’', 349), ('trump', 334), ('that', 302), ('i', 251), ('is', 235), ('1', 235), ('for', 221), ('s', 216), ('it', 215), ('on', 212), ('positive', 188), ('with', 175), ('donald', 155), ('this', 147), ('like', 145), ('we', 141), ('by', 140), ('more', 139), ('at', 133), ('neutral', 133), ('percent', 127), ('but', 126), ('as', 125), ('are', 118), ('—', 118), ('you', 114), ('from', 101), ('was', 100), ('/', 99), ('about', 97), ('have', 93), ('be', 91), ('than', 90), ('or', 85), ('negative', 82), ('has', 81), ('hillary', 79), ('one', 78), ('data', 76), ('his', 76), ("'m", 75), ('an', 74), ('my', 74), ('state', 74), ('not', 73), ('“', 69), ('”', 69), ('t', 69), ('model', 68), ('me', 66), ('polls', 65), ('they', 63), ('he', 62), ('up', 61), ("'s", 60), ('were', 60), ('all', 59), ('?', 59), ('so', 58), ('how', 56), ('can', 56), ('other', 56), (';', 54), ('there', 52), ('when', 52), ('get', 51), ('which', 51), ('their', 51), ('some', 51), ('if', 50), ('out', 50), ('clinton', 50), ("n't", 49), ('just', 48), ('2015', 47), ('2', 47), ('most', 46), ('what', 46), ('who', 45), ('people', 45), ('2013', 44), ('points', 44), ('do', 43), ('2014', 42), ('only', 41), ('those', 41)]

Applied pre-processing:
Lowercased all tokens 
Tokens below minimum token length 1 filtered out
Punctuation filtered out ['!', '"', '#', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '~', '“', '’', '”', '—', "'"]
Words filtered out: ['facebooktwitteremail', '']

Applied filters: 
bigrams = False
lemmatize = False
minimumtokenlength = 1
showuniquepostagtokens = True
stemmer = False
stopwords = True
trigrams = False

Token analysis after pre-processing 
Number of tokens: 294
Number of types: 197
Type token ratio: 0.6700680272108843

Used nouns, verbs and adjectives in article: 
(tokens separated by , ) 
('NN', 'jessie, video, stephen, child, unisex, mona, nate, jun, determine, number, baby, percent, work, jody, chalabi, ratio, difference, casey, infantof, june, gap, analysis, list, article, state, ssa, cooper, code, version, data, thing, woman, maletofemale, chart, security, silver, split, placeholder, explore, pm, infant, explanation, bell, edit, nba, conference, example, man, curry, administration, column, value, colleague, prevalent, riley, peyton, daughter, philadelphia, jackie, mvp, story, andrew, clarification, receiver, name, method')

('JJ', 'ambiguous, male, previous, golden, living, unisex, actuarial, hard, female, unnamed, searchable, getty, github, much, percent, likely, unknown, table, pat, recent, androgynous, total, social, mccann, excluded, similar, maximum, infant, press, onethird, top, able, wide, adorable, common, threshold, enough, riley, minimum, sure, full, name')

('NNS', 'flowers, americans, records, shares, others, colleagues, america, men, newborns, years, names, sexes, data, women, dataunisexnames, people, github, warriors, rings, tables')

('VBP', 'identify, approximate, america, make, riley, allison, postgame, create, ssa, set, alive, result, github, name, say')

('VBD', 'cut, ranked, filed, notnamed, thought, added, balanced, set, unnamed, excluded, left')

('VB', 'get, saw, take, kerry')

('VBN', 'used, removed, named, done, adjusted, taken, given')

('VBG', 'living, thinking, using, building')

('VBZ', 'turns, lists, shows, means, eagles')

('JJS', 'least')

('JJR', 'earlier, lower')

100 most freq tokens after processing: 
[('verdict', 378), ('trump', 340), ('1', 242), ('positive', 188), ('donald', 159), ('like', 151), ('percent', 135), ('neutral', 133), ('one', 87), ('negative', 82), ('hillary', 80), ('data', 79), ('state', 77), ('polls', 68), ('model', 68), ('get', 57), ('nt', 54), ('clinton', 53), ('people', 51), ('2', 51), ('2015', 49), ('would', 45), ('2014', 44), ('2013', 44), ('points', 44), ('also', 43), ('2012', 43), ('number', 41), ('2016', 41), ('got', 40), ('police', 39), ('average', 39), ('time', 37), ('much', 37), ('year', 37), ('bill', 37), ('election', 35), ('new', 34), ('10', 34), ('obama', 34), ('3', 34), ('github', 33), ('fuck', 33), ('2008', 33), ('drivers', 33), ('weather', 33), ('senate', 32), ('president', 31), ('make', 31), ('two', 31), ('even', 31), ('money', 31), ('candidate', 31), ('said', 30), ('day', 30), ('way', 29), ('republican', 29), ('win', 29), ('polling', 29), ('gorsuch', 29), ('think', 28), ('likely', 28), ('5', 28), ('fivethirtyeight', 28), ('2010', 27), ('candidates', 27), ('know', 26), ('cases', 26), ('percentage', 26), ('puerto', 26), ('years', 25), ('every', 25), ('show', 25), ('based', 25), ('tower', 25), ('big', 25), ('2011', 25), ('rico', 25), ('last', 24), ('example', 24), ('poll', 24), ('need', 23), ('officers', 23), ('black', 23), ('ai', 23), ('remix', 23), ('first', 22), ('bitch', 22), ('estimate', 22), ('forecast', 22), ('circuit', 22), ('want', 21), ('well', 21), ('us', 21), ('states', 21), ('city', 21), ('2000', 21), ('still', 21), ('however', 21), ('man', 21)]
