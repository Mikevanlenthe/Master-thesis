Article: us-weather-history

Tokenized by nltk.word_tokenize 
Token analysis before pre-processing 
Raw number of tokens: 521
Raw number of types: 247
Raw Type token ratio: 0.4740882917466411

100 most freq tokens before (pre)processing: 
[(',', 3559), ('the', 2449), ('.', 1387), ('of', 1144), ('a', 1004), ('in', 947), ('to', 905), ('(', 841), (')', 841), ('and', 815), ('’', 673), ("'", 664), (':', 594), ('that', 533), ('our', 442), ('s', 408), ('is', 393), ('for', 377), ('verdict', 377), ('on', 374), ('it', 372), ('trump', 357), ('i', 296), ('with', 282), ('1', 281), ('at', 260), ('—', 243), ('are', 241), ('more', 240), ('percent', 237), ('by', 233), ('but', 225), ('as', 219), ('we', 218), ('this', 212), ('“', 210), ('”', 210), ('than', 189), ('positive', 189), ('have', 183), ('like', 177), ('from', 175), ('you', 164), ('about', 162), ('was', 162), ('donald', 159), ('data', 154), ('or', 154), ('an', 145), ('they', 141), ('t', 138), ('be', 133), ('neutral', 133), ('has', 127), ('one', 126), ('all', 109), ('their', 109), ('/', 108), ('out', 107), ('who', 107), ('not', 106), ('other', 106), ('were', 103), ('so', 101), ('when', 100), ('most', 99), ('people', 97), ('get', 95), ('which', 95), ('what', 94), ('?', 93), ('up', 93), ('there', 92), ('his', 91), ('some', 88), ('can', 88), ('he', 86), ('2', 86), ('how', 85), ('those', 85), ('if', 84), ('my', 84), ('negative', 83), ('hillary', 81), (';', 79), ('state', 79), ('me', 78), ('model', 77), ('films', 77), ('do', 76), ('only', 76), ("'m", 75), ('just', 73), ('3', 71), ('also', 70), ('its', 68), ('polls', 66), ('github', 65), ('10', 65), ('said', 64)]

Applied pre-processing:
Lowercased all tokens 
Tokens below minimum token length 1 filtered out
Punctuation filtered out ['!', '"', '#', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '~', '“', '’', '”', '—', "'"]
Words filtered out: ['facebooktwitteremail', '']

Applied filters: 
bigrams = False
lemmatize = False
minimumtokenlength = 1
showuniquepostagtokens = True
stemmer = False
stopwords = True
trigrams = False

Token analysis after pre-processing 
Number of tokens: 269
Number of types: 183
Type token ratio: 0.6802973977695167

Used nouns, verbs and adjectives in article: 
(tokens separated by , ) 
('NNS', 'cities, records, months, others, temperatures, feels, angeles, dots, times, states, carolina, waves, highs, chicago, days, snaps, charts, data, digits, parts')

('VBG', 'recordsetting, setting, saying, beginning, studying')

('VBZ', 'consequences, highs, looks')

('VBP', 'cold, houston, hotter, weather, randy, make, take, show, march, november, indicate')

('VBN', 'recorded, returned, expected, filed, released, updated, published')

('NN', 'weather, part, http, record, day, stateofclimate, view, tell2, github, temperature, houston, june, york, tcodjwfrfmmjp, period, show, cold, chart, pictwittercomxpj8rfr8bs, heat, half, world, janjune, spike, globe, change, july, way, country, datausweatherhistory, fact, city, year, detail, seattle, aggregate, spectrum, high, administration, get, report, climate, see, story, end, range, winter')

('JJ', 'atmospheric, previous, low, single, oceanic, record, several, los, national, january, different, hot, affect, curious, north, odd, upper, unique, noaa, warm, clear, past, blue, uncomfortable, cold, consistent, justright, lasting, general, famous, average, noaanceiclimate, charlotte, large, click, normal, high, actual, broad, handful, us1, new, february, western, united, many, particular, last')

('JJS', 'best, hottest, warmest')

('VBD', 'experienced, cold, red, soared, looked, reached, examined, sat')

('VB', 'expand, set, feel')

100 most freq tokens after processing: 
[('verdict', 378), ('trump', 363), ('1', 294), ('percent', 245), ('positive', 189), ('like', 183), ('donald', 163), ('data', 157), ('one', 135), ('neutral', 133), ('people', 103), ('get', 101), ('2', 92), ('negative', 83), ('state', 82), ('hillary', 82), ('10', 79), ('3', 79), ('model', 77), ('films', 77), ('also', 73), ('said', 70), ('polls', 69), ('new', 66), ('5', 66), ('github', 65), ('women', 64), ('would', 61), ('2015', 61), ('rock', 61), ('time', 59), ('year', 59), ('film', 58), ('2014', 58), ('two', 57), ('clinton', 57), ('nt', 55), ('6', 55), ('much', 53), ('2016', 53), ('number', 52), ('police', 52), ('2013', 51), ('got', 49), ('likely', 49), ('average', 49), ('2012', 48), ('points', 48), ('4', 47), ('even', 46), ('classic', 46), ('us', 45), ('first', 45), ('see', 45), ('years', 44), ('make', 43), ('way', 43), ('last', 43), ('test', 42), ('among', 42), ('bill', 42), ('republican', 41), ('obama', 40), ('day', 40), ('national', 40), ('think', 39), ('candidates', 39), ('every', 38), ('8', 38), ('still', 38), ('election', 38), ('9', 38), ('president', 37), ('7', 37), ('know', 36), ('many', 36), ('money', 36), ('20', 36), ('example', 36), ('set', 36), ('since', 36), ('15', 36), ('use', 36), ('weather', 36), ('senate', 36), ('big', 35), ('men', 35), ('percentage', 35), ('well', 34), ('three', 34), ('numbers', 34), ('least', 34), ('based', 34), ('2008', 34), ('candidate', 34), ('according', 34), ('less', 34), ('movie', 34), ('may', 33), ('12', 33)]
