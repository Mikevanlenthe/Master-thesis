Tokenized by nltk.word_tokenize 
Token analysis before pre-processing 
Raw number of tokens: 327
Raw number of types: 174
Raw Type token ratio: 0.5321100917431193

Applied pre-processing:
Lowercased all tokens 
Punctuation filtered out ['!', '"', '#', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '~', '“', '’', '”', '—', "'"]
Words filtered out: ['facebooktwitteremail', '']

Applied filters:
Using stopwords filter = True
Using lemmatizer = True
Using stemmer = True

Token analysis after pre-processing 
Number of tokens: 124
Number of types: 88
Type token ratio: 0.7096774193548387

Used nouns, verbs and adjectives in article: 
(tokens separated by whitespace) 
('JJ', 'publish tuesday surveymonkey south make excit column live southern midwestern local midwestern inabl resid send walterhickey fivethirtyeightcom whole nebul')

('NNS', 'data data respons data data pleas data data')

('JJS', 'midwest midwest midwest')

('NN', 'walt hickey file remix interest post wednesday result audienc poll state make avail github github page survey head tail mean file folk inform respond code incom gender region interest approach interest peopl languag analysi respond word especi interest approach code expatri definit region agre core state difficulttocategor state missouri virginia ident remix post articl ross bechdel test result fantast remix interest thing research kickoff point question point endeavor particularli region insight appreci')

('VBD', 'wrote format split')

('VBP', 'make find explain want explain send find learn')

('VB', 'make ask post')

