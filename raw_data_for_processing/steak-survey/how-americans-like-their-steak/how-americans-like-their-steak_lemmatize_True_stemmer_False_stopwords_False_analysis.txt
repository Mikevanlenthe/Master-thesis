Tokenized by nltk.word_tokenize 
Token analysis before pre-processing 
Raw number of tokens: 653
Raw number of types: 299
Raw Type token ratio: 0.45788667687595713

Applied pre-processing:
Lowercased all tokens 
Punctuation filtered out ['!', '"', '#', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '~', '“', '’', '”', '—', "'"]
Words filtered out: ['facebooktwitteremail', '']

Applied filters:
Using stopwords filter = False
Using lemmatizer = True
Using stemmer = False

Token analysis after pre-processing 
Number of tokens: 326
Number of types: 214
Type token ratio: 0.656441717791411

Used nouns, verbs and adjectives in article: 
(tokens separated by whitespace) 
('JJ', 'american prime baked green bean nina dandy likely full personal rare surveymonkey fresh sense actual frivolous moral proper lacked foodborne different interpret simple behavior gender insignificant laughable small doe respondent hypothetical likely vast ballpark many good')

('NN', 'steak walt hickey fivethirtyate github github potato almondine cruise ship scott suchman post riskaverse order steak idea commitment disclosure quest opportunity discus superiority steak story datalab audience poll work satisfaction experiment argument definition superiority girl scout america steak wound rest look time life steak mediumrare sense commitment order steak reason side medium reason le juicy steak threat illness everyone threshold risk speed limit survey risk traffic smoke lottery steak result place start nothing regression tease relationship steak rareness income effect relationship survey relationship steak example consider situation lottery chance success payout lottery chance success payout lottery steak rare anything futility chart respondent steak majority percent medium mediumrare mediumwell anyone hypothesis steak taste idea comment download anything')

('VBN', 'filed done tried been incinerated cooked percent percent solid scorched')

('NNS', 'data data datasteaksurvey people data people people people data crosstabs people people people people besides')

('VBZ', 'washington midteens data')

('VBP', 'have find miss have have prefer stand prefer jump exceed evaluate prefer prefer appear risk like have have prefer have know know know')

('VBG', 'reinforcing playing running settling testing skydiving getting risktaking following assuming indicating preferring')

('VB', 'come recover realize have play')

('JJS', 'midwest least')

('VBD', 'cooked ordered speed asked excited checked checked were asked thought picked gained preferred desiccated')

('JJR', 'tougher riskier riskier')

